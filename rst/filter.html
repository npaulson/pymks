
<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Filter Example &mdash; PyMKS</title>
    
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootswatch-3.3.6/cosmo/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pymks.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.3.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.6/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="shortcut icon" href="../_static/pymks_logo.ico"/>
    <link rel="top" title="PyMKS" href="../index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">


  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><img src="../_static/pymks_logo.png">
          PyMKS</a>
        <span class="navbar-text navbar-version pull-left"><b>0.3.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="INSTALLATION.html">Installation</a></li>
                <li><a href="../EXAMPLES.html">Examples</a></li>
                <li><a href="../API.html">API</a></li>
                <li><a href="https://github.com/materialsinnovation/pymks/">Github</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">More <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../THEORY.html">Theory</a><ul>
<li class="toctree-l2"><a class="reference internal" href="derivation.html">Derivation of MKS Localization Equation</a></li>
<li class="toctree-l2"><a class="reference internal" href="tech_overview.html">Technical Overview</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="CREDITS.html">Authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="LICENSE.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="CITATION.html">Citing</a></li>
<li class="toctree-l1"><a class="reference internal" href="REQUIREMENTS.html">Requirements</a></li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          

        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="filter-example">
<h1>Filter Example<a class="headerlink" href="#filter-example" title="Permalink to this headline">Â¶</a></h1>
<p>This example demonstrates the connection between MKS and signal
processing for a 1D filter. It shows that the filter is in fact the same
as the influence coefficients and, thus, applying the <code class="docutils literal"><span class="pre">predict</span></code> method
provided by the <code class="docutils literal"><span class="pre">MKSLocalizationnModel</span></code> is in essence just applying a
filter.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span></span>if __import__(&#39;pyfftw&#39;):
    import pyfftw
%matplotlib inline
%load_ext autoreload
%autoreload 2

import numpy as np
import matplotlib.pyplot as plt
</pre></div>
</div>
<p>Here we construct a filter, <span class="math">\(F\)</span>, such that</p>
<div class="math">
\[F\left(x\right) = e^{-|x|} \cos{\left(2\pi x\right)}\]</div>
<p>We want to show that, if <span class="math">\(F\)</span> is used to generate sample
calibration data for the MKS, then the calculated influence coefficients
are in fact just <span class="math">\(F\)</span>.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span></span><span class="n">x0</span> <span class="o">=</span> <span class="o">-</span><span class="mf">10.</span>
<span class="n">x1</span> <span class="o">=</span> <span class="mf">10.</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">F</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">F</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#1a9850&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/filter_3_0.png" src="../_images/filter_3_0.png" />
<p>Next we generate the sample data <code class="docutils literal"><span class="pre">(X,</span> <span class="pre">y)</span></code> using
<code class="docutils literal"><span class="pre">scipy.ndimage.convolve</span></code>. This performs the convolution</p>
<div class="math">
\[p\left[ s \right] = \sum_r F\left[r\right] X\left[r - s\right]\]</div>
<p>for each sample.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.ndimage</span>


<span class="n">n_space</span> <span class="o">=</span> <span class="mi">101</span>
<span class="n">n_sample</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">201</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">n_space</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">n_sample</span><span class="p">,</span> <span class="n">n_space</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">scipy</span><span class="o">.</span><span class="n">ndimage</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">F</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;wrap&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">X</span><span class="p">])</span>
</pre></div>
</div>
<p>For this problem, a basis is unnecessary, as no discretization is
required in order to reproduce the convolution with the MKS
localization. Using the <code class="docutils literal"><span class="pre">ContinuousIndicatorBasis</span></code> with <code class="docutils literal"><span class="pre">n_states=2</span></code>
is the equivalent of a non-discretized convolution in space.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pymks</span> <span class="kn">import</span> <span class="n">MKSLocalizationModel</span>
<span class="kn">from</span> <span class="nn">pymks</span> <span class="kn">import</span> <span class="n">PrimitiveBasis</span>

<span class="n">p_basis</span> <span class="o">=</span> <span class="n">PrimitiveBasis</span><span class="p">(</span><span class="n">n_states</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MKSLocalizationModel</span><span class="p">(</span><span class="n">basis</span><span class="o">=</span><span class="n">p_basis</span><span class="p">)</span>
</pre></div>
</div>
<p>Fit the model using the data generated by <span class="math">\(F\)</span>.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>To check for internal consistency, we can compare the predicted output
with the original for a few values</p>
<div class="code python highlight-python"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">print</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">4</span><span class="p">]</span>
<span class="k">print</span> <span class="n">y_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">4</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span>[-0.41059557  0.20004566  0.61200171  0.5878077 ]
[-0.41059557  0.20004566  0.61200171  0.5878077 ]
</pre></div>
</div>
<p>With a slight linear manipulation of the coefficients, they agree
perfectly with the shape of the filter, <span class="math">\(F\)</span>.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">F</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">r&#39;$F$&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#1a9850&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
         <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">r&#39;$\alpha$&#39;</span><span class="p">)</span>
<span class="n">l</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/filter_13_0.png" src="../_images/filter_13_0.png" />
<p>Some manipulation of the coefficients is required to reproduce the
filter. Remember the convolution for the MKS is</p>
<div class="math">
\[p \left[s\right] = \sum_{l=0}^{L-1} \sum_{r=0}^{S - 1} \alpha[l, r] m[l, s - r]\]</div>
<p>However, when the primitive basis is selected, the
<code class="docutils literal"><span class="pre">MKSLocalizationModel</span></code> solves a modified form of this. There are
always redundant coefficients since</p>
<div class="math">
\[\sum\limits_{l=0}^{L-1} m[l, s] = 1\]</div>
<p>Thus, the regression in Fourier space must be done with categorical
variables, and the regression takes the following form:</p>
<div class="math">
\[\begin{split} \begin{split}
p [s] &amp; = \sum_{l=0}^{L - 1} \sum_{r=0}^{S - 1} \alpha[l, r] m[l, s -r] \\
P [k] &amp; = \sum_{l=0}^{L - 1} \beta[l, k] M[l, k] \\
&amp;= \beta[0, k] M[0, k] + \beta[1, k] M[1, k]
\end{split}\end{split}\]</div>
<p>where</p>
<div class="math">
\[\begin{split}\beta[0, k] = \begin{cases}
\langle F(x) \rangle ,&amp; \text{if } k = 0\\
0,              &amp; \text{otherwise}
\end{cases}\end{split}\]</div>
<p>This removes the redundancies from the regression, and we can reproduce
the filter.</p>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>